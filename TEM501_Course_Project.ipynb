{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEM501 course project\n",
    "\n",
    "In this document, I will give instrustions to perform following tasks related to the course project.\n",
    "\n",
    "- Load data from data files\n",
    "- Split development data into dev-train/dev-test data\n",
    "- Preprocess and extract features from meta-data of images\n",
    "- Select top features from the training data\n",
    "- Build a simple baseline for the course project\n",
    "\n",
    "## Loading data\n",
    "\n",
    "We will load meta-data and labels of images in the development set. In this simple version, I only use `description`, `title` and `user_tags` in meta-data of images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You may need to change the path to the data\n",
    "devset_meta_data = \"./data/course_project/devset/devset_images_metadata.json\"\n",
    "devset_gt_data = \"./data/course_project/devset/devset_images_gt.csv\"\n",
    "path_to_output_csv = \"./data/course_project/devset/devset_images_bow.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a class `ImageMetaData` to store info of each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageMetaData():\n",
    "    \n",
    "    def __init__(self, img_id, description, title, user_tags):\n",
    "        self.img_id = img_id\n",
    "        self.description = description if description is not None else \"\"\n",
    "        self.title = title if title is not None else \"\"\n",
    "        self.user_tags = user_tags if user_tags is not None else []\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return str(self.__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following functions will load meta-data and labels of images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def load_meta_data(file_path):\n",
    "    with open(file_path) as f:\n",
    "        json_object = json.load(f)\n",
    "        images = json_object[\"images\"]\n",
    "    data = []\n",
    "    for img in images:\n",
    "        img_meta = ImageMetaData(img[\"image_id\"], img[\"description\"], img[\"title\"], img[\"user_tags\"])\n",
    "        data.append(img_meta)\n",
    "    return data\n",
    "\n",
    "def load_label(file_path):\n",
    "    \"\"\"Load gold-standard labels\n",
    "    \n",
    "    Return\n",
    "    -------\n",
    "    img2label: Map from image id to its label\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file_path, header=None)\n",
    "    img2label = { str(img_id):int(lb) for img_id,lb in zip(df[0], df[1]) }\n",
    "    return img2label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to load meta data and labels in the developement set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 4224\n",
      "[{'img_id': '3595468464', 'description': '', 'title': 'Sukhumvit Soi 4, Nana Tai, Bangkok', 'user_tags': ['7d', 'asia', 'bangkok', 'capital', 'city', 'dynax', 'earth asia', 'food', 'foodstall', 'konica', 'maxxum', 'minolta', 'nana', 'people', 'road', 'soi', 'street', 'sukhumvit', 'thailand', 'urban']}, {'img_id': '5090153632', 'description': 'The Arno crosses Florence, where it passes below the Ponte Vecchio and the Santa Trìnita bridge (built by Bartolomeo Ammanati, but inspired by Michelangelo). The river flooded this city regularly in historical times, the last occasion being the famous flood of 1966, with 4,500 m³/s after a rain of 437.2 mm in Badia Agnano and 190 millimetres in Florence, in only 24 hours.', 'title': 'Florence, Italy', 'user_tags': ['arno', 'duomo', 'florence', 'italy', 'ponte vecchio', 'tuscany']}, {'img_id': '5893636276', 'description': 'Straight maile road', 'title': '4 BATTI 4 RASTA', 'user_tags': ['jamshedpur']}]\n"
     ]
    }
   ],
   "source": [
    "devset_data = load_meta_data(devset_meta_data)\n",
    "print(\"Number of images: {}\".format(len(devset_data)))\n",
    "\n",
    "# See some first images\n",
    "print(devset_data[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n"
     ]
    }
   ],
   "source": [
    "img2label = load_label(devset_gt_data)\n",
    "print(img2label[\"3595468464\"], img2label[\"5090153632\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data spliting\n",
    "\n",
    "For system development, we always want to split the devset into dev-train and dev-test. We will do that by using `scikit-learn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'img_id': '2268582059', 'description': '', 'title': 'P1070591', 'user_tags': ['burningmax', 'national', 'park', 'road', 'roadtrip', 'states', 'trash', 'trip', 'united', 'usa', 'utah', 'west', 'zion']}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "img_labels = [img2label[img.img_id] for img in devset_data]\n",
    "\n",
    "dev_train_data, dev_test_data, dev_train_labels, dev_test_labels = train_test_split(devset_data, img_labels,\n",
    "                                                                                  test_size=0.25, random_state=42\n",
    "                                                                                  )\n",
    "print(dev_train_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing and feature extraction\n",
    "\n",
    "In this section, we will perform data preprocessing and feature extraction. We just perform basic text cleaning and use BoW features from description, title, and user tags of images. **More advanced preprocessing and feature extraction is left for students**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"Clean text\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    text: A String\n",
    "\n",
    "    Return\n",
    "    -----------\n",
    "    text_: A String\n",
    "        The text after being cleaned\n",
    "    \"\"\"\n",
    "    ANY_URL_REGEX = r\"\"\"(?i)\\b((?:[a-z][\\w-]+:(?:/{1,3}|[a-z0-9%])|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\".,<>?«»“”‘’]))\"\"\"\n",
    "    WEB_URL_REGEX = r\"\"\"(?i)\\b((?:https?:(?:/{1,3}|[a-z0-9%])|[a-z0-9.\\-]+[.](?:com|net|org|edu|gov|mil|aero|asia|biz|cat|coop|info|int|jobs|mobi|museum|name|post|pro|tel|travel|xxx|ac|ad|ae|af|ag|ai|al|am|an|ao|aq|ar|as|at|au|aw|ax|az|ba|bb|bd|be|bf|bg|bh|bi|bj|bm|bn|bo|br|bs|bt|bv|bw|by|bz|ca|cc|cd|cf|cg|ch|ci|ck|cl|cm|cn|co|cr|cs|cu|cv|cx|cy|cz|dd|de|dj|dk|dm|do|dz|ec|ee|eg|eh|er|es|et|eu|fi|fj|fk|fm|fo|fr|ga|gb|gd|ge|gf|gg|gh|gi|gl|gm|gn|gp|gq|gr|gs|gt|gu|gw|gy|hk|hm|hn|hr|ht|hu|id|ie|il|im|in|io|iq|ir|is|it|je|jm|jo|jp|ke|kg|kh|ki|km|kn|kp|kr|kw|ky|kz|la|lb|lc|li|lk|lr|ls|lt|lu|lv|ly|ma|mc|md|me|mg|mh|mk|ml|mm|mn|mo|mp|mq|mr|ms|mt|mu|mv|mw|mx|my|mz|na|nc|ne|nf|ng|ni|nl|no|np|nr|nu|nz|om|pa|pe|pf|pg|ph|pk|pl|pm|pn|pr|ps|pt|pw|py|qa|re|ro|rs|ru|rw|sa|sb|sc|sd|se|sg|sh|si|sj|Ja|sk|sl|sm|sn|so|sr|ss|st|su|sv|sx|sy|sz|tc|td|tf|tg|th|tj|tk|tl|tm|tn|to|tp|tr|tt|tv|tw|tz|ua|ug|uk|us|uy|uz|va|vc|ve|vg|vi|vn|vu|wf|ws|ye|yt|yu|za|zm|zw)/)(?:[^\\s()<>{}\\[\\]]+|\\([^\\s()]*?\\([^\\s()]+\\)[^\\s()]*?\\)|\\([^\\s]+?\\))+(?:\\([^\\s()]*?\\([^\\s()]+\\)[^\\s()]*?\\)|\\([^\\s]+?\\)|[^\\s`!()\\[\\]{};:'\".,<>?«»“”‘’])|(?:(?<!@)[a-z0-9]+(?:[.\\-][a-z0-9]+)*[.](?:com|net|org|edu|gov|mil|aero|asia|biz|cat|coop|info|int|jobs|mobi|museum|name|post|pro|tel|travel|xxx|ac|ad|ae|af|ag|ai|al|am|an|ao|aq|ar|as|at|au|aw|ax|az|ba|bb|bd|be|bf|bg|bh|bi|bj|bm|bn|bo|br|bs|bt|bv|bw|by|bz|ca|cc|cd|cf|cg|ch|ci|ck|cl|cm|cn|co|cr|cs|cu|cv|cx|cy|cz|dd|de|dj|dk|dm|do|dz|ec|ee|eg|eh|er|es|et|eu|fi|fj|fk|fm|fo|fr|ga|gb|gd|ge|gf|gg|gh|gi|gl|gm|gn|gp|gq|gr|gs|gt|gu|gw|gy|hk|hm|hn|hr|ht|hu|id|ie|il|im|in|io|iq|ir|is|it|je|jm|jo|jp|ke|kg|kh|ki|km|kn|kp|kr|kw|ky|kz|la|lb|lc|li|lk|lr|ls|lt|lu|lv|ly|ma|mc|md|me|mg|mh|mk|ml|mm|mn|mo|mp|mq|mr|ms|mt|mu|mv|mw|mx|my|mz|na|nc|ne|nf|ng|ni|nl|no|np|nr|nu|nz|om|pa|pe|pf|pg|ph|pk|pl|pm|pn|pr|ps|pt|pw|py|qa|re|ro|rs|ru|rw|sa|sb|sc|sd|se|sg|sh|si|sj|Ja|sk|sl|sm|sn|so|sr|ss|st|su|sv|sx|sy|sz|tc|td|tf|tg|th|tj|tk|tl|tm|tn|to|tp|tr|tt|tv|tw|tz|ua|ug|uk|us|uy|uz|va|vc|ve|vg|vi|vn|vu|wf|ws|ye|yt|yu|za|zm|zw)\\b/?(?!@)))\"\"\"\n",
    "    \n",
    "    text_ = text.strip()\n",
    "    \n",
    "    regx_list  = [\n",
    "        # Remove text between <a href=>...</a>\n",
    "        re.compile(r\"<a href=\\\".+?\\\".*?>.*?</a>\"),\n",
    "    ]\n",
    "    for rgx in regx_list:\n",
    "        text_ = re.sub(rgx, \" \", text_)\n",
    "    # Remove HTML links\n",
    "    text_ = re.sub(WEB_URL_REGEX, \" \", text_)\n",
    "    text_ = re.sub(ANY_URL_REGEX, \" \", text_)\n",
    "    return text_\n",
    "\n",
    "    \n",
    "def extract_bow_features(img):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    -----------\n",
    "    img: An ImageMetaData object\n",
    "    \n",
    "    Return\n",
    "    -----------\n",
    "    tokenized string that includes BoW in title, description, and user_tags\n",
    "    \"\"\"\n",
    "    tokens = []\n",
    "    for text in [ img.title, img.description ]:\n",
    "        if text == \"\":\n",
    "            continue\n",
    "        text = clean_text(text)\n",
    "        tokens += word_tokenize(text)\n",
    "        \n",
    "    for tag in img.user_tags:\n",
    "        tag = clean_text(tag)\n",
    "        if tag == \"\":\n",
    "            continue\n",
    "        tag = \"_\".join(tag.split())\n",
    "        tokens.append(tag)\n",
    "\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We test the `extract_bow_features` on some images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P1070591 burningmax national park road roadtrip states trash trip united usa utah west zion\n",
      "P9290020 canoe flooding hue katsana mekong minska motorbike river travel typhoon veitnam water wet\n"
     ]
    }
   ],
   "source": [
    "print(extract_bow_features(dev_train_data[0]))\n",
    "print(extract_bow_features(dev_train_data[1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top feature selection\n",
    "\n",
    "Now, we will use scikit-learn (See [http://scikit-learn.org/stable/modules/feature_selection.html](http://scikit-learn.org/stable/modules/feature_selection.html) and [http://scikit-learn.org/stable/auto_examples/feature_selection/plot_feature_selection.html](http://scikit-learn.org/stable/auto_examples/feature_selection/plot_feature_selection.html)) to select some good features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['flood', 'flooded', 'building', 'flooding', 'water', 'rain', 'road', 'floods', 'storm', 'city', 'construction', 'architecture', 'site', 'bridge', 'old', 'people', 'new', 'irene', 'weather', 'built']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "import numpy as np\n",
    "\n",
    "vectorizer = CountVectorizer(\n",
    "                             binary=True,   # Use binary features\n",
    "                             stop_words=\"english\"\n",
    "                            ) \n",
    "dev_train_bow = [extract_bow_features(img) for img in dev_train_data]\n",
    "X_train = vectorizer.fit_transform(dev_train_bow)\n",
    "fs = SelectKBest(chi2, k=100)\n",
    "X_new = fs.fit_transform(X_train, dev_train_labels)\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "sorted_features = [feature_names[i] for i in np.argsort(fs.scores_)[::-1]]\n",
    "print(sorted_features[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple baseline system\n",
    "\n",
    "Now we will build a simple baseline system. The system uses weigted sum of top features as the score of an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_score(img, weights):\n",
    "    score = 0.0\n",
    "    bow = extract_bow_features(img)\n",
    "    for w in bow:\n",
    "        if w in weights:\n",
    "            score += weightes[w]\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use the `baseline_score` to sort the images in the `dev_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'flood': 1, 'flooded': 0.95, 'building': 0.8999999999999999, 'flooding': 0.8499999999999999, 'water': 0.7999999999999998, 'rain': 0.7499999999999998, 'road': 0.6999999999999997, 'floods': 0.6499999999999997, 'storm': 0.5999999999999996, 'city': 0.5499999999999996, 'construction': 0.4999999999999996, 'architecture': 0.4499999999999996, 'site': 0.39999999999999963, 'bridge': 0.34999999999999964, 'old': 0.29999999999999966}\n"
     ]
    }
   ],
   "source": [
    "top_features = sorted_features[:15]\n",
    "weights = {}\n",
    "wei = 1\n",
    "step = 0.05\n",
    "for w in top_features:\n",
    "    weights[w] = wei\n",
    "    wei -= step\n",
    "print(weights)\n",
    "    \n",
    "sorted_images = sorted(dev_test_data, key=lambda x: baseline_score(x, weights), reverse=True)\n",
    "sorted_image_ids = [img.img_id for img in sorted_images]\n",
    "sorted_image_labels = [img2label[img_id] for img_id in sorted_image_ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will use the following function to calculate the average precision at `k`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "def average_precision_at_k(k, doc_labels):\n",
    "    \"\"\"Average Precision at k\n",
    "    \"\"\"\n",
    "    k = min(k, len(doc_labels))\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "\n",
    "    for i,p in enumerate(doc_labels[:k]):\n",
    "        if p == 1:\n",
    "            num_hits += 1\n",
    "            score += num_hits / (i+1.0)\n",
    "    if num_hits == 0:\n",
    "        return 0.0\n",
    "    return score/num_hits\n",
    "\n",
    "def report_result(ranked_gt_labels):\n",
    "    cutoff = 480\n",
    "    cutoff_vals = [50, 100, 250, 480]\n",
    "\n",
    "    avg_prec_at_k = 100*average_precision_at_k(cutoff, ranked_gt_labels)\n",
    "    print(\"AP@{} = {} %\".format(cutoff, avg_prec_at_k))\n",
    "\n",
    "    scores = []\n",
    "    for k in cutoff_vals:\n",
    "        avg_prec = 100.0 * average_precision_at_k(k, ranked_gt_labels)\n",
    "        print('AP@%d = %f' % (k, avg_prec))\n",
    "        scores.append(avg_prec)\n",
    "    avg = numpy.mean(scores)\n",
    "    print(\"Mean AP@ [{}] = {}\".format(\", \".join([str(x) for x in cutoff_vals]), avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AP@480 = 34.00006388442876 %\n",
      "AP@50 = 36.727798\n",
      "AP@100 = 33.951794\n",
      "AP@250 = 33.986380\n",
      "AP@480 = 34.000064\n",
      "Mean AP@ [50, 100, 250, 480] = 34.66650922088554\n"
     ]
    }
   ],
   "source": [
    "report_result(sorted_image_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applications of the baseline for the test set\n",
    "\n",
    "Now we will use the baseline system for test set data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'flood': 1, 'building': 0.95, 'flooded': 0.8999999999999999, 'flooding': 0.8499999999999999, 'water': 0.7999999999999998, 'rain': 0.7499999999999998, 'road': 0.6999999999999997, 'floods': 0.6499999999999997, 'architecture': 0.5999999999999996, 'city': 0.5499999999999996, 'storm': 0.4999999999999996, 'construction': 0.4499999999999996, 'site': 0.39999999999999963, 'bridge': 0.34999999999999964, 'old': 0.29999999999999966}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "import numpy as np\n",
    "\n",
    "vectorizer = CountVectorizer(\n",
    "                             binary=True,   # Use binary features\n",
    "                             stop_words=\"english\"\n",
    "                            ) \n",
    "train_bow = [extract_bow_features(img) for img in devset_data]\n",
    "X_train = vectorizer.fit_transform(train_bow)\n",
    "fs = SelectKBest(chi2, k=2)\n",
    "fs.fit(X_train, img_labels)\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "sorted_features = [feature_names[i] for i in np.argsort(fs.scores_)[::-1]]\n",
    "top_features = sorted_features[:15]\n",
    "\n",
    "weights = {}\n",
    "wei = 1\n",
    "step = 0.05\n",
    "for w in top_features:\n",
    "    weights[w] = wei\n",
    "    wei -= step\n",
    "print(weights)\n",
    "\n",
    "path_to_test_metadata = \"./data/course_project/testset/testset_images_metadata.json\"\n",
    "path_to_test_label = \"./data/course_project/testset/testset_images_gt.csv\"\n",
    "testset_data = load_meta_data(path_to_test_metadata)\n",
    "test_img2label = load_label(path_to_test_label)\n",
    "\n",
    "sorted_images = sorted(testset_data, key=lambda x: baseline_score(x, weights), reverse=True)\n",
    "sorted_image_ids = [img.img_id for img in sorted_images]\n",
    "sorted_image_labels = [test_img2label[img_id] for img_id in sorted_image_ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we report the result of the baseline system on the test set data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AP@480 = 35.792911181924495 %\n",
      "AP@50 = 51.742616\n",
      "AP@100 = 42.246260\n",
      "AP@250 = 37.323844\n",
      "AP@480 = 35.792911\n",
      "Mean AP@ [50, 100, 250, 480] = 41.77640771764484\n"
     ]
    }
   ],
   "source": [
    "report_result(sorted_image_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random baseline\n",
    "\n",
    "Now let's try a random baseline which sort the image ids in the testset randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AP@480 = 36.29854208586498 %\n",
      "AP@50 = 41.706019\n",
      "AP@100 = 39.961639\n",
      "AP@250 = 36.702047\n",
      "AP@480 = 36.298542\n",
      "Mean AP@ [50, 100, 250, 480] = 38.6670617885098\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(1337)\n",
    "\n",
    "image_ids = list( test_img2label.keys() )\n",
    "random.shuffle(image_ids)\n",
    "image_labels = [test_img2label[img_id] for img_id in image_ids]\n",
    "report_result(image_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
