{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text categorization with logistic regression and other methods\n",
    "\n",
    "TEM501 - Text Mining\n",
    "\n",
    "## Outline\n",
    "\n",
    "In this document, I will give instructions of how to do text categorization with logistic regression and other text categorization algorithms with scikit-learn toolkit.\n",
    "\n",
    "We will learn:\n",
    "\n",
    "- How to implement `sigmoid` function\n",
    "- How to use scikit-learn for feature extraction and train a text categorization model\n",
    "- How to output probabilities for a prediction\n",
    "- Get top features with highest weights in a trained logistic regression model\n",
    "- Try other text categorization methods (such as SVM)\n",
    "\n",
    "We use the sentiment data in this document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of sigmoid function\n",
    "\n",
    "In this exercise, please implement `sigmoid` function as follows. Recall that, the sigmoid function is calculated as follows.\n",
    "\n",
    "$$\n",
    "\\sigma(z)=\\frac{1}{1+e^{-z}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# z can be np.ndarray, np.matrix, or scalar\n",
    "def sigmoid(z):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Data\n",
    "\n",
    "We use the [sentence polarity dataset v1.0](http://www.cs.cornell.edu/people/pabo/movie-review-data/rt-polaritydata.README.1.0.txt) from [Moview Review Data](http://www.cs.cornell.edu/people/pabo/movie-review-data/) of Bo Pang v√† Lillian Lee. We can see the data file in [./data/sentiment.txt](./data/sentiment.txt).\n",
    "\n",
    "Each line in the file is a review which was already tokenized into words. Each review has a label (+1 for positive review and -1 for negative review).\n",
    "\n",
    "\n",
    "## Loading data\n",
    "\n",
    "We will load the data into a list of tuples $(d, c)$ in which $d$ denote a document and $c$ denotes the label of the document. We define the function `load_data` as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def load_data(file_path):\n",
    "    data = []\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line == \"\":\n",
    "                continue\n",
    "            match = re.search(r\"(\\+1|-1)[\\s\\t]+(.+)$\", line)  # match the line +1 ...\n",
    "            if match:\n",
    "                lb = match.group(1)\n",
    "                sentence = match.group(2)\n",
    "                if sentence == \"\":\n",
    "                    continue\n",
    "                data.append((sentence,lb))\n",
    "    return data\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the above function to load sentiment data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Loaded 10662 examples\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = \"./data/sentiment.txt\"\n",
    "data = load_data(DATA_PATH)\n",
    "\n",
    "print(\"# Loaded {} examples\".format(len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also split data into training/test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training reviews: 8529\n",
      "Test reviews: 2133\n",
      "Random positive review\n",
      "if you can tolerate the redneck-versus-blueblood cliches that the film trades in , sweet home alabama is diverting in the manner of jeff foxworthy's stand-up act .\n",
      "Random negative review\n",
      "what's next ? rob schneider , dana carvey and sarah michelle gellar in the philadelphia story ? david spade as citizen kane ?\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = load_data(DATA_PATH)\n",
    "docs, labels = zip(*data)\n",
    "\n",
    "train_docs, test_docs, train_labels, test_labels = train_test_split(docs, labels,\n",
    "                                                                   test_size=0.2,\n",
    "                                                                   random_state=1337)\n",
    "print(\"Training reviews: {}\".format(len(train_docs)))\n",
    "print(\"Test reviews: {}\".format(len(test_docs)))\n",
    "\n",
    "# Let's see some positive and negative documents in test data.\n",
    "posi_docs = []\n",
    "neg_docs = []\n",
    "for d, lb in zip(test_docs, test_labels):\n",
    "    if lb == \"+1\":\n",
    "        posi_docs.append(d)\n",
    "    else:\n",
    "        neg_docs.append(d)\n",
    "\n",
    "print(\"Random positive review\")\n",
    "print(random.choice(posi_docs))\n",
    "print(\"Random negative review\")\n",
    "print(random.choice(neg_docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using scikit-learn for feature extraction\n",
    "\n",
    "We can use scikit-learn for [feature extraction](http://scikit-learn.org/stable/modules/feature_extraction.html). We use the bag-of-word representation for feature extraction. In scikit-learn, we can use `CountVectorizer` or `TfidfTransformer`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extraction with CountVectorizer\n",
    "\n",
    "We will use the class `CounterVectorizer` for feature extraction. Since the data was alreay tokenized, we do not to pass `tokenizer` or `token_pattern` arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=True, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(\n",
    "                             binary=True,   # Use binary features\n",
    "                             stop_words=\"english\"\n",
    "                            ) \n",
    "vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we fit the vectorizer object on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = vectorizer.fit_transform(train_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We we try the `vectorizer` to get BoW of a sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['text', 'document', 'analyze']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze = vectorizer.build_analyzer()\n",
    "analyze(\"This is a text document to analyze.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text categorization with logistic regression\n",
    "\n",
    "Now let's try text categorization with [logistic regression implementation](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) in scikit-learn. See the document [here](http://scikit-learn.org/stable/modules/linear_model.html#logistic-regression) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we fit the model on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation on test set\n",
    "\n",
    "Now let's evaluate the model on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = vectorizer.transform(test_docs)\n",
    "test_preds = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Test accuracy: 0.7463666197843413\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "accuracy = metrics.accuracy_score(test_labels, test_preds)\n",
    "print(\"# Test accuracy: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can predict the label for an input review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: ['+1']\n"
     ]
    }
   ],
   "source": [
    "example = \"a thoughtful , provocative , insistently humanizing film .\"\n",
    "test_x = vectorizer.transform([example])\n",
    "print(\"Predicted class: {}\".format(clf.predict(test_x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get prediction probabilties\n",
    "\n",
    "In some cases, we would like to get prediction probabilities. For instance, in the course project, we would like to rank images by the descending order of the probability that an image includes a flooding event.\n",
    "\n",
    "We can do that by using the method `predict_proba`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.77033746, 0.22966254]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first value is the probability that the instance belongs to the class \"+1\" and the second value is the probability that the instance belongs to the class \"-1\".\n",
    "Let's try a negative review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.27721876, 0.72278124]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example2 = \"for all its surface frenzy , high crimes should be charged with loitering -- so much on view , so little to offer .\"\n",
    "test_x2 = vectorizer.transform([example2])\n",
    "clf.predict_proba(test_x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can combine probability values with a threshold $t$ to customize our prediction. For instance, we can decide that the prediction is \"+1\" if the probability is greater than 0.6 instead of 0.5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get top features with the highest weights\n",
    "\n",
    "In this section, we would like to see top features with the highest weights.\n",
    "\n",
    "First, we get all features in vectorizer and target_names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 [[ 0.1401822   0.13881197  0.2241502  ...  0.15164946 -0.01178921\n",
      "   0.23204102]]\n"
     ]
    }
   ],
   "source": [
    "feature_names = vectorizer.get_feature_names()\n",
    "target_names = [\"+1\", \"-1\"]\n",
    "print(len(clf.coef_), clf.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 50 keywords:\n",
      "mess woody repetitive episode indulgent pretentious attempts superficial tedious merit exhausting unfunny excuse seagal bland lack jokes ill thinks advice save junk stunt supposed pie product badly bad unless numbers generic disguise plodding devoid tries incoherent flat bore tv busy wasn routine mildly fails mediocre waste intentions worst boring dull\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "topN = 50\n",
    "print(\"top {} keywords:\".format(topN))\n",
    "top10 = np.argsort(clf.coef_[0])[-topN:]\n",
    "top_features = [ feature_names[i] for i in top10 ]\n",
    "print(\" \".join(top_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try with n-gram features\n",
    "\n",
    "Now we would like to use unigram and bigram features in feature extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Test accuracy: 0.7430848570089077\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(binary=True,\n",
    "                             stop_words=\"english\",\n",
    "                             ngram_range=(1,2),\n",
    "                            ) \n",
    "X_train = vectorizer.fit_transform(train_docs)\n",
    "\n",
    "clf.fit(X_train, train_labels)\n",
    "\n",
    "X_test = vectorizer.transform(test_docs)\n",
    "test_preds = clf.predict(X_test)\n",
    "\n",
    "accuracy = metrics.accuracy_score(test_labels, test_preds)\n",
    "print(\"# Test accuracy: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try with tf-idf term weighting\n",
    "\n",
    "Now, we use tf-idf term weighting for feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Test accuracy: 0.7374589779653071\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5,\n",
    "                             stop_words='english')\n",
    "X_train = vectorizer.fit_transform(train_docs)\n",
    "\n",
    "clf.fit(X_train, train_labels)\n",
    "\n",
    "X_test = vectorizer.transform(test_docs)\n",
    "test_preds = clf.predict(X_test)\n",
    "\n",
    "accuracy = metrics.accuracy_score(test_labels, test_preds)\n",
    "print(\"# Test accuracy: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using SVM for text categorization\n",
    "\n",
    "In this section, we would like to use SVM for text categorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Test accuracy: 0.720112517580872\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "vectorizer = CountVectorizer(binary=True,\n",
    "                             stop_words=\"english\",\n",
    "                             # ngram_range=(1,2),\n",
    "                            ) \n",
    "\n",
    "clf = LinearSVC(loss='squared_hinge', penalty=\"l2\",\n",
    "                dual=False, tol=1e-3)\n",
    "\n",
    "X_train = vectorizer.fit_transform(train_docs)\n",
    "\n",
    "clf.fit(X_train, train_labels)\n",
    "\n",
    "X_test = vectorizer.transform(test_docs)\n",
    "test_preds = clf.predict(X_test)\n",
    "\n",
    "accuracy = metrics.accuracy_score(test_labels, test_preds)\n",
    "print(\"# Test accuracy: {}\".format(accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "1. Try different text categorization algorithms in scikit-learn such as `KNeighborsClassifier`, `DecisionTreeClassifier` for the sentiment data.\n",
    "2. Load the development data of the course project, then extract BoW features for description, title, and user tags in eac"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
